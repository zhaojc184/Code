{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bd32e4-54d9-476c-a1c1-f02432497f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import numpy as np\n",
    "import geatpy as ea\n",
    "import pandas as pd\n",
    "from numpy import exp\n",
    "from scipy.optimize import linprog\n",
    "import time\n",
    "import FragStatsPy.frag_model as fspy\n",
    "import geopandas as gpd\n",
    "import rasterio as rio\n",
    "import shutil\n",
    "import joblib\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c86ebc-7226-4e17-829e-e0e1da05e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "isa_filepath = r'E:\\Paper4_new2\\d_isa_raster\\isa.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d822c2-9d40-4e7e-b2da-3078c633f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(isa_filepath) as src1:\n",
    "    profile = src1.profile\n",
    "    width, height = src1.width, src1.height\n",
    "    ISA_2d = src1.read(1)\n",
    "    nodata_value = src1.nodata\n",
    "print(\"Nodata value：\", nodata_value)\n",
    "print('Figure width,height：', height, width,)\n",
    "print(ISA_2d.shape)\n",
    "not_Nodata_count = len(ISA_2d[ISA_2d != nodata_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32749841-f877-4c3c-b0f0-0a7a889dfd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ISA_1d = ISA_2d.flatten()\n",
    "isa_optim = ISA_1d[np.where(ISA_1d != nodata_value)]\n",
    "ISA_area_SUM = isa_optim.sum()\n",
    "print(isa_optim)\n",
    "print(isa_optim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e622b321-b530-41a3-bff5-71060dee3aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "inter2 = np.where(ISA_2d == nodata_value, True, False)\n",
    "print(inter2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c50baf9-d6bd-4c71-a0a9-9436f46833d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dem = 'E:/Paper4_new2/f_dem_slope_guanwang/'\n",
    "file_names = ['dem.tif', 'guanwang.tif', 'slope.tif', 'water.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed60622-bcd1-412a-8ab4-4910753f7faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_other = np.empty((len(file_names), not_Nodata_count))\n",
    "factor_other.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ffdc09-d407-4341-9954-3cc806f9a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_other = np.empty((len(file_names), not_Nodata_count))\n",
    "\n",
    "for i, file_name in enumerate(file_names):\n",
    "    file_path = filepath_dem + file_name\n",
    "    with rio.open(file_path) as src:\n",
    "        data = src.read(1)\n",
    "        data[inter2] = np.array([-999]).astype(data.dtype)\n",
    "        data = data.flatten()\n",
    "        factor_other[i, :] = data[data != -999]\n",
    "Fac = np.transpose(factor_other)\n",
    "factors_dem = (Fac - Fac.min(axis=0)) / (Fac.max(axis=0) - Fac.min(axis=0))\n",
    "print(factors_dem.shape)\n",
    "print(factors_dem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd143b5-95f6-4a9c-80af-b61c9428f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_fca = r'E:\\Paper4_new2\\h_couple_code\\unnamed1250.fca'\n",
    "filepath_Chongfenlei = r'E:\\Paper4_new2\\h_couple_code\\isa_ChongFenLei.tif'\n",
    "filepath_tifmw1 = 'E:/Paper4_new2/h_couple_code/isa_chongfenlei.tif_mw1/'\n",
    "landscape_name = ['pland_1.tif', 'pland_2.tif', 'pland_3.tif', 'pland_4.tif',\n",
    "                  'pland_5.tif',\n",
    "                  'ai_1.tif', 'ai_2.tif', 'ai_3.tif', 'ai_4.tif', 'ai_5.tif',\n",
    "                  'para_mn_1.tif', 'para_mn_2.tif', 'para_mn_3.tif',\n",
    "                  'para_mn_4.tif', 'para_mn_5.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258dfc1b-5af3-4311-b930-5470543a6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chongfenlei = np.zeros_like(ISA_2d)\n",
    "chongfenlei[ISA_2d == nodata_value] = nodata_value\n",
    "chongfenlei[(ISA_2d >= 0) & (ISA_2d <= 0.2)] = 1\n",
    "chongfenlei[(ISA_2d > 0.2) & (ISA_2d <= 0.4)] = 2\n",
    "chongfenlei[(ISA_2d > 0.4) & (ISA_2d <= 0.6)] = 3\n",
    "chongfenlei[(ISA_2d > 0.6) & (ISA_2d <= 0.8)] = 4\n",
    "chongfenlei[ISA_2d > 0.8] = 5\n",
    "with rio.open(filepath_Chongfenlei, 'w', **profile) as dst:\n",
    "    dst.write(chongfenlei, 1)\n",
    "model = fspy.FragModel(filepath_fca)\n",
    "model.load_landscape_layer(filepath_Chongfenlei)\n",
    "model.set_output_base_path(r'E:\\Paper4_new2\\shanchu')\n",
    "model.run_model()\n",
    "\n",
    "folder_path = filepath_tifmw1\n",
    "w = len(landscape_name)\n",
    "\n",
    "landscape = np.empty((not_Nodata_count, w+1))\n",
    "\n",
    "for i, file_name in enumerate(landscape_name):\n",
    "    file_path = folder_path + file_name\n",
    "    with rio.open(file_path) as src:\n",
    "        data = src.read(1)\n",
    "        data[inter2] = nodata_value\n",
    "        data = data.flatten()\n",
    "        landscape[:, i] = data[data != nodata_value]\n",
    "\n",
    "isa_density = ISA_2d[np.where(ISA_2d != nodata_value)]\n",
    "landscape[:, w] = isa_density\n",
    "\n",
    "landscape[landscape == -999] = np.nan\n",
    "min_vals = np.nanmin(landscape, axis=0)\n",
    "max_vals = np.nanmax(landscape, axis=0)\n",
    "\n",
    "factors_nor = (landscape - min_vals) / (max_vals - min_vals)\n",
    "factors_nor[np.isnan(factors_nor)] = 0\n",
    "\n",
    "factors_merged = np.concatenate((factors_dem, factors_nor), axis=1)\n",
    "print(factors_merged.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed58404f-2cbe-45b9-aa24-e3fcfa116476",
   "metadata": {},
   "outputs": [],
   "source": [
    "lightgbm_model_file_path = r'E:\\Paper4_new2\\g_MLearning\\lightgbm01.pkl'\n",
    "filepath_risk = r'E:\\Paper4_new2\\h_couple_code\\raster\\Ori_Risk_250.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6f008c-628a-4997-bf91-0085af9ddf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = lightgbm_model_file_path\n",
    "lgb_clf_best1 = joblib.load(model_path)\n",
    "pred = lgb_clf_best1.predict_proba(factors_merged)[:, 1]\n",
    "ori_risk_sum = pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fd1190-28a2-4dd3-85d7-6fd32a8c676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ISA_1d[np.where(ISA_1d != nodata_value)] = pred\n",
    "ISA_2d_1 = ISA_1d.reshape(height, width)\n",
    "with rio.open(filepath_risk, 'w', **profile) as dst:\n",
    "    dst.write(ISA_2d_1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0865b6d-63a3-48fb-8c3a-d69a85a80876",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_cfl = 'E:/Paper4_new2/h_couple_code/objective_function/cfl.tif'\n",
    "filepath_fca = r'E:\\Paper4_new2\\h_couple_code\\unnamed1250.fca'\n",
    "filepath_landscape = 'E:/Paper4_new2/h_couple_code/objective_function/cfl.tif_mw1/'\n",
    "\n",
    "landscape_name = ['pland_1.tif', 'pland_2.tif', 'pland_3.tif', 'pland_4.tif',\n",
    "                  'pland_5.tif',\n",
    "                  'ai_1.tif', 'ai_2.tif', 'ai_3.tif', 'ai_4.tif', 'ai_5.tif',\n",
    "                  'para_mn_1.tif', 'para_mn_2.tif', 'para_mn_3.tif',\n",
    "                  'para_mn_4.tif', 'para_mn_5.tif']\n",
    "filepath_delete_mwl = 'E:/Paper4_new2/h_couple_code/objective_function/cfl.tif_mw1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7522d90-a2b4-4c8b-b9b7-b18e762c73d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(Vars):\n",
    "    for m in range(0, NIND):\n",
    "        array1 = Vars[m, :]/xiaoshu\n",
    "        ISA_1d[np.where(ISA_1d != nodata_value)] = array1\n",
    "        ISA_2d_1 = ISA_1d.reshape(height, width)\n",
    "        chongfenlei = np.zeros_like(ISA_2d_1)\n",
    "        chongfenlei[ISA_2d_1 == nodata_value] = nodata_value\n",
    "        chongfenlei[(ISA_2d_1 >= 0) & (ISA_2d_1 <= 0.2)] = 1\n",
    "        chongfenlei[(ISA_2d_1 > 0.2) & (ISA_2d_1 <= 0.4)] = 2\n",
    "        chongfenlei[(ISA_2d_1 > 0.4) & (ISA_2d_1 <= 0.6)] = 3\n",
    "        chongfenlei[(ISA_2d_1 > 0.6) & (ISA_2d_1 <= 0.8)] = 4\n",
    "        chongfenlei[ISA_2d_1 > 0.8] = 5\n",
    "        with rio.open(filepath_cfl, 'w', **profile) as dst:\n",
    "            dst.write(chongfenlei, 1)\n",
    "\n",
    "        model = fspy.FragModel(filepath_fca)\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "        model.load_landscape_layer(filepath_cfl)\n",
    "        model.set_output_base_path(r'F:\\01')\n",
    "        model.run_model()\n",
    "        sys.stdout = old_stdout\n",
    "        w = len(landscape_name)\n",
    "        landscape = np.empty((not_Nodata_count, w+1))\n",
    "        for i, file_name in enumerate(landscape_name):\n",
    "            file_path = filepath_landscape + file_name\n",
    "            with rio.open(file_path) as src:\n",
    "                data = src.read(1)\n",
    "                data[inter2] = nodata_value\n",
    "                data = data.flatten()\n",
    "                landscape[:, i] = data[data != nodata_value]\n",
    "\n",
    "        isa_density = ISA_2d_1[np.where(ISA_2d_1 != nodata_value)]\n",
    "        landscape[:, w] = isa_density\n",
    "        landscape[landscape == -999] = np.nan\n",
    "        factors_nor = (landscape - min_vals) / (max_vals - min_vals)\n",
    "        factors_nor[np.isnan(factors_nor)] = 0\n",
    "        factors_merged = np.concatenate((factors_dem, factors_nor), axis=1)\n",
    "        model_path = lightgbm_model_file_path\n",
    "        lgb_clf_best1 = joblib.load(model_path)\n",
    "        pred = lgb_clf_best1.predict_proba(factors_merged)[:, 1]\n",
    "        obj[m, :] = pred\n",
    "        shutil.rmtree(filepath_delete_mwl)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162c95a5-2775-426b-a0a0-c9ec33012396",
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoding = 'RI'\n",
    "NIND = 500\n",
    "maximum_iterations = 600\n",
    "bianyi_coefficient = 0.1\n",
    "jiaocha_coefficient = 0.7\n",
    "log = 1\n",
    "filepath_result = 'E:/Paper4_new2/i_optim_result/NIND'\n",
    "ISA_SUM_per = 0.95\n",
    "xia_ISA_per = 0.7\n",
    "shang_ISA_per = 0.7\n",
    "xiaoshu = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ca5a2a-3e13-44d9-a23b-e4a748954869",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_var1 = (isa_optim*xiaoshu).round().astype(int)\n",
    "print(ori_var1.sum())\n",
    "print(ori_var1[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9003ce9b-bcc5-4115-9405-982c93d71727",
   "metadata": {},
   "outputs": [],
   "source": [
    "ISA_SUM_shang = ori_var1.sum()\n",
    "ISA_SUM_xia = int(ISA_SUM_shang*ISA_SUM_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75f48c7-cf27-4b72-92b4-c673f19da19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = np.empty((NIND, not_Nodata_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c628ad36-e451-4b4b-8556-cd07b9c45e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_green_water = r'E:\\Paper4_new2\\h_couple_code\\banArea_new1\\green_water.tif'\n",
    "filtpath_road = r'E:\\Paper4_new2\\h_couple_code\\banArea_new1\\road.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eaa825-65df-44b4-9568-ee1e0bcfb486",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(filepath_green_water) as src1:\n",
    "    profile = src1.profile\n",
    "    width, height = src1.width, src1.height\n",
    "    green_2d = src1.read(1)\n",
    "    nodata_value = src1.nodata\n",
    "green_1d = green_2d.flatten()\n",
    "not_Nodata_count = len(green_2d[green_2d != nodata_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae77ca21-f7cd-409b-8879-cbb312b3a8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(filtpath_road) as src1:\n",
    "    profile = src1.profile\n",
    "    width, height = src1.width, src1.height\n",
    "    road_2d = src1.read(1)\n",
    "    nodata_value = src1.nodata\n",
    "\n",
    "road_1d = road_2d.flatten()\n",
    "not_Nodata_count = len(road_2d[road_2d != nodata_value])\n",
    "print(\"Nodata value：\", nodata_value)\n",
    "print('width,height：', height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc06ba5-ee51-4c05-844c-2febf2381fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "green1 = green_1d[np.where(green_1d != nodata_value)]\n",
    "#green2 = (green1*100).round().astype(int)\n",
    "sj_green = 1-green1\n",
    "print('-------------------------------------------')\n",
    "road1 = road_1d[np.where(road_1d != nodata_value)]\n",
    "print('---------------------------')\n",
    "m = [sj_green[i] - road1[i] for i in range(len(sj_green))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68d911a-370d-4ec8-ba7e-5a7ce3a05fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sj = (isa_optim*shang_ISA_per+1-shang_ISA_per).tolist()\n",
    "xj = (isa_optim*shang_ISA_per).tolist()\n",
    "shangjie1 = [sj[i] if sj[i] < sj_green[i] else sj_green[i] for i in range(len(sj))]\n",
    "xiajie1 = [road1[i] if xj[i] < road1[i] else xj[i] for i in range(len(xj))]\n",
    "print(shangjie1[0:10])\n",
    "print(sum(shangjie1))\n",
    "print('--------------------------')\n",
    "print(xiajie1[0:10])\n",
    "print(sum(xiajie1))\n",
    "print('---------------------------')\n",
    "chazhi = [shangjie1[i] - xiajie1[i] for i in range(len(sj_green))]\n",
    "print(min(chazhi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e26317-d5f4-4428-b52e-ea2799394ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shangjie = [round(num * 100) for num in shangjie1]\n",
    "xiajie = [round(num * 100) for num in xiajie1]\n",
    "chazhi = [shangjie[i] - xiajie[i] for i in range(len(sj_green))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b174116c-1b35-4838-b27b-04290daf2515",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyProblem(ea.Problem):\n",
    "    def __init__(self):\n",
    "        name = 'BNH'\n",
    "        M = 2\n",
    "        maxormins = [1] * M\n",
    "        Dim = not_Nodata_count\n",
    "        varTypes = [1] * Dim\n",
    "        lb = xiajie\n",
    "        ub = shangjie\n",
    "        lbin = [1] * Dim\n",
    "        ubin = [1] * Dim\n",
    "        ea.Problem.__init__(self, name, M, maxormins, Dim, varTypes, lb, ub, lbin, ubin)\n",
    "\n",
    "    def aimFunc(self, pop):\n",
    "        Vars = pop.Phen\n",
    "        obj = objective(Vars)\n",
    "        f1 = np.sum(obj, axis=1)\n",
    "        f2 = np.absolute(np.sum(Vars, axis=1) - 875990)\n",
    "        pop.ObjV = np.hstack((f1[:, np.newaxis], f2[:, np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed433aa1-f317-4a82-818e-275dee3d4609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "problem = MyProblem()\n",
    "#\n",
    "Field = ea.crtfld(Encoding, problem.varTypes, problem.ranges, problem.borders)\n",
    "population = ea.Population(Encoding, Field, NIND)\n",
    "\"\"\"=========================Algorithm parameter setting============================\"\"\"\n",
    "myAlgorithm = ea.moea_NSGA2_templet(problem, population)\n",
    "myAlgorithm.mutOper.Pm = bianyi_coefficient\n",
    "myAlgorithm.recOper.XOVR = jiaocha_coefficient\n",
    "myAlgorithm.MAXGEN = maximum_iterations\n",
    "myAlgorithm.logTras = log\n",
    "myAlgorithm.verbose = True\n",
    "myAlgorithm.drawing = 1\n",
    "\"\"\"========================================\n",
    "\"\"\"\n",
    "[NDSet, population] = myAlgorithm.run()\n",
    "NDSet.save(filepath_result)\n",
    "\"\"\"===========================output result========================\"\"\"\n",
    "print('time：%s s' % myAlgorithm.passTime)\n",
    "print('Number of non-dominant individuals：%d 个' % NDSet.sizes) if NDSet.sizes !=0 else print('No feasible solution was found！')\n",
    "if myAlgorithm.log is not None and NDSet.sizes != 0:\n",
    "    print('GD', myAlgorithm.log['gd'][-1])\n",
    "    print('IGD', myAlgorithm.log['igd'][-1])\n",
    "    print('HV', myAlgorithm.log['hv'][-1])\n",
    "    print('Spacing', myAlgorithm.log['spacing'][-1])\n",
    "\"\"\"======================Evolutionary process index tracking analysis==================\"\"\"\n",
    "metricName = [['igd'], ['hv']]\n",
    "Metrics = np.array([myAlgorithm.log[metricName[i][0]] for i in range(len(metricName))]).T\n",
    "ea.trcplot(Metrics, labels=metricName, titles=metricName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e174cb60-1b18-4285-ad8b-df248628180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_variable = pd.read_csv(r'E:\\Paper4_new2\\shanchu\\Phen.csv', header = None)\n",
    "df_ObjV = pd.read_csv(r'E:\\Paper4_new2\\shanchu\\ObjV.csv', header = None)\n",
    "df_ObjV.columns = ['f1_risk', 'f2_isa_sum']\n",
    "df_ov = pd.concat([df_ObjV, df_variable], axis=1)\n",
    "df_ov1 = df_ov.loc[df_ov.f2_isa_sum == df_ov['f2_isa_sum'].min()]\n",
    "pp = df_ov1.values\n",
    "pp = pp[0, 2:]\n",
    "pp = pp/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d00827-9bf2-471d-a554-ea77305e0346",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_isa_optimization = r'E:\\Paper4_new2\\i_optim_result\\isa_optim_result.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fb94fe-1e3a-4fbd-a7d6-c47d9a25039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ISA_1d[np.where(ISA_1d != nodata_value)] = pp\n",
    "ISA_2d = ISA_1d.reshape(height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277a6043-4091-4ef9-9032-2b836c3eaf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with rio.open(filepath_isa_optimization, 'w', **profile) as dst:\n",
    "    dst.write(ISA_2d, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8576a332-1b7b-4f67-a40e-fefdf3bd9ec4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my310",
   "language": "python",
   "name": "my310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
